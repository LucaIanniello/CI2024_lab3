{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "from heapq import heappop, heappush, nsmallest\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "RANDOMIZE_STEPS = 1000\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "def is_goal(state: np.ndarray) -> bool:\n",
    "    \"\"\"Check if the state matches the goal configuration.\"\"\"\n",
    "    goal = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "    return np.array_equal(state, goal)\n",
    "\n",
    "def difference_from_goal(state: np.ndarray) -> int:\n",
    "    \"\"\"Calculate the difference between the current state and the goal state.\"\"\"\n",
    "    goal = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "    return np.sum(state != goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Approach done is the A* search algorithm, where the heuristic function is the Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(state: np.ndarray) -> int:\n",
    "    \"\"\"Calculate the Manhattan distance of the current state to the goal state.\"\"\"\n",
    "    distance = 0\n",
    "    goal_positions = {i: (i // PUZZLE_DIM, i % PUZZLE_DIM) for i in range(1, PUZZLE_DIM ** 2)}\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x, y]\n",
    "            if value != 0:\n",
    "                goal_x, goal_y = goal_positions[value]\n",
    "                distance += abs(x - goal_x) + abs(y - goal_y)\n",
    "    return distance\n",
    "\n",
    "def linear_conflict(state: np.ndarray) -> int:\n",
    "    conflict = 0\n",
    "    for i in range(PUZZLE_DIM):\n",
    "        row = state[i, :]\n",
    "        col = state[:, i]\n",
    "        conflict += sum((x > y) for j, x in enumerate(row) for y in row[j + 1:])\n",
    "        conflict += sum((x > y) for j, x in enumerate(col) for y in col[j + 1:])\n",
    "    return conflict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_star(initial_state: np.ndarray):\n",
    "    \"\"\"Solve the puzzle using A* search with a priority queue (heapq).\"\"\"\n",
    "    open_list = []\n",
    "    heappush(open_list, (manhattan_distance(initial_state), initial_state.tobytes(), []))\n",
    "    closed_set = set()\n",
    "    closed_set.add(initial_state.tobytes())  # Use byte representation for consistency\n",
    "\n",
    "    while open_list:\n",
    "        # Pop the state with the lowest heuristic value\n",
    "        heuristic, current_state_bytes, path = heappop(open_list)\n",
    "        current_state = np.frombuffer(current_state_bytes, dtype=int).reshape(initial_state.shape)\n",
    "\n",
    "        # Check if the goal state is reached\n",
    "        if is_goal(current_state):\n",
    "            return path, len(path), len(closed_set)\n",
    "\n",
    "        # Generate successors\n",
    "        for action in available_actions(current_state):\n",
    "            next_state = do_action(current_state, action)\n",
    "            next_state_bytes = next_state.tobytes()\n",
    "\n",
    "            # Only process unvisited states\n",
    "            if next_state_bytes not in closed_set:\n",
    "                next_path = path + [action]\n",
    "                priority = manhattan_distance(next_state) + 2*linear_conflict(next_state)+ len(next_path)  # A* evaluation: f(n) = g(n) + h(n)\n",
    "                heappush(open_list, (priority, next_state_bytes, next_path))\n",
    "                closed_set.add(next_state_bytes)\n",
    "\n",
    "    # If the goal is unreachable\n",
    "    return None, -1, len(closed_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(state: np.ndarray, beam_size: int):\n",
    "    \"\"\"Solve the puzzle using Beam Search with randomized action selection.\"\"\"\n",
    "    priority_queue = []\n",
    "    visited = set()\n",
    "    total_nodes_evaluated = 0\n",
    "\n",
    "    initial_priority = difference_from_goal(state)\n",
    "    heappush(priority_queue, (initial_priority, tuple(map(tuple, state))))\n",
    "\n",
    "    while priority_queue and not is_goal(state):\n",
    "        priority, state_tuple = heappop(priority_queue)\n",
    "        state = np.array(state_tuple)\n",
    "        \n",
    "        visited.add(state_tuple)\n",
    "\n",
    "        if is_goal(state):\n",
    "            return state, total_nodes_evaluated, len(visited)\n",
    "\n",
    "        for _ in range(beam_size):\n",
    "            new_state = do_action(state, choice(available_actions(state)))\n",
    "            new_state_tuple = tuple(map(tuple, new_state))\n",
    "\n",
    "            if new_state_tuple not in visited:\n",
    "                priority = (\n",
    "                    0.8 * difference_from_goal(new_state) +\n",
    "                    0.2 * manhattan_distance(new_state)\n",
    "                )\n",
    "                heappush(priority_queue, (priority, new_state_tuple))\n",
    "                total_nodes_evaluated += 1\n",
    "\n",
    "    return state, total_nodes_evaluated, len(visited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e5db6d06eb4b3e998c2d66ccef414a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Randomizing:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "[[4 1 7]\n",
      " [3 5 8]\n",
      " [6 2 0]]\n",
      "A* Solution path: [Action(pos1=(2, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 2)), Action(pos1=(2, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(0, 0)), Action(pos1=(0, 0), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(0, 2)), Action(pos1=(0, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(0, 0)), Action(pos1=(0, 0), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 0)), Action(pos1=(2, 0), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(0, 0)), Action(pos1=(0, 0), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(0, 2)), Action(pos1=(0, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(2, 2)), Action(pos1=(2, 2), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(2, 2))]\n",
      "Quality (number of moves): 28\n",
      "Cost (total nodes evaluated): 27194\n",
      "Beam search Solution path:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Quality (number of moves): 8505\n",
      "Cost (total nodes evaluated): 1033\n"
     ]
    }
   ],
   "source": [
    "# Initialize and randomize the starting state\n",
    "initial_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for _ in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    initial_state = do_action(initial_state, choice(available_actions(initial_state)))\n",
    "\n",
    "print(\"Initial state:\")\n",
    "print(initial_state)\n",
    "# Solve the puzzle\n",
    "solution_path, quality, cost = A_star(initial_state)\n",
    "\n",
    "\n",
    "print(\"A* Solution path:\", solution_path)\n",
    "print(\"Quality (number of moves):\", quality)\n",
    "print(\"Cost (total nodes evaluated):\", cost)\n",
    "\n",
    "solution_path,quality,cost = beam_search(initial_state,4)\n",
    "print(\"Beam search Solution path:\\n\", solution_path)\n",
    "print(\"Quality (number of moves):\", quality)\n",
    "print(\"Cost (total nodes evaluated):\", cost)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-zvPL2sNt-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
